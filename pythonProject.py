import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# â€”â€”â€” CONFIG â€”â€”â€”
#This stores the path to your CSV file. The r before the string makes it a raw string to handle backslashes properly in file paths.

CSV_PATH = r"C:\Users\kushw\OneDrive\Documents\Downloads\Air_Quality (1).csv"

# â€”â€”â€” 1) LOAD & CLEAN â€”â€”â€”
# Loads the dataset into a DataFrame called df.
df = pd.read_csv(CSV_PATH)
#Cleans the column names by removing spaces and replacing them with underscores for easier access.
df.columns = df.columns.str.strip().str.replace(" ", "_")

#Drops any column that contains only NaN values.
df.dropna(axis=1, how="all", inplace=True)

#Fills any remaining NaN values with the previous value in the column (forward fill).
df.ffill(inplace=True)           # futureâ€‘proof over df.fillna(method="ffill")

df.drop_duplicates(inplace=True)

# â€”â€”â€” 2) 2) DESCRIPTIVE STATISTICS â€”â€”â€”
#Selects all numeric columns and calculates statistics like mean, min, max, standard deviation, etc.
numeric_cols = df.select_dtypes(include=[np.number]).columns
desc_stats = df[numeric_cols].describe()
print("\nâ–¶ Descriptive statistics for numeric columns:\n")
print(desc_stats, "\n")


# â€”â€”â€” 3) PIVOT TABLE (top 10) â€”â€”â€”
#Creates a pivot table showing average pollution values (Data_Value) for each Measure (like PM2.5, CO) across different places.
pivot_data = df.pivot_table(
    values="Data_Value",
    index="Geo_Place_Name",
    columns="Measure",
    aggfunc="mean"
)
print("â–¶ Pivot table (average Data_Value) â€” top 10 places:\n")
print(pivot_data.head(10), "\n") #Prints the top 10 rows of the pivot table

# â€”â€”â€” 4) LINE PLOT â€”â€”â€”
#Transposes the top 10 rows and creates a line plot showing trends of different measures across top 10 cities.
plt.figure(figsize=(10, 5))
sns.lineplot(data=pivot_data.head(10).T)
plt.title("Measures across Top 10 Locations")
plt.xlabel("Measure")
plt.ylabel("Average Data Value")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show() #Displays a clear line chart comparing pollution measures across cities.

# â€”â€”â€” 5) TOP 6 CITIES (pie chart) â€”â€”â€”
#Displays a pie chart showing how data is distributed across the top 6 cities.
top_cities = df["Geo_Place_Name"].value_counts().head(6)
print("â–¶ Top 6 cities by number of records:\n")
print(top_cities, "\n")

plt.figure(figsize=(6, 6))
plt.pie(top_cities.values,
        labels=top_cities.index,
        autopct="%1.1f%%",
        startangle=140)
plt.title("Distribution of Top 6 Cities")
plt.axis("equal")
plt.tight_layout()
plt.show()

# â€”â€”â€” 6) TOP 10 POLLUTANTS (bar chart) â€”â€”â€”
#Calculates and prints the average value of each pollutant, then shows the top 10.
top_pollutants = (df.groupby("Measure")["Data_Value"]
                    .mean()
                    .sort_values(ascending=False)
                    .head(10))
print("â–¶ Top 10 pollutants by average value:\n")
print(top_pollutants, "\n")

plt.figure(figsize=(8, 6))
sns.barplot(x=top_pollutants.values, y=top_pollutants.index)
plt.title("Top 10 Pollutants by Average Value")
plt.xlabel("Average Data Value")
plt.ylabel("Pollutant")
plt.tight_layout()
plt.show() #Displays a horizontal bar chart of pollutants with highest average values.

# â€”â€”â€” 7) CORRELATION MATRIX â€”â€”â€”
# Calculates and prints how much numeric columns are correlated with each other.
corr = df[numeric_cols].corr()
print("â–¶ Correlation matrix of numeric features:\n")
print(corr, "\n")

plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap="coolwarm", fmt=".2f")
plt.title("Correlation Heatmap")
plt.tight_layout()
plt.show() 
#Shows a heatmap where:
#Red = Strong positive correlation
#Blue = Strong negative correlation

# â€”â€”â€” 8) SCENARIO COLUMNS & TOP CITY â€”â€”â€”
# Creates two new columns:
#One assuming a 20% increase in pollution
#Another assuming a 20% decrease
df["Scenario_High"] = df["Data_Value"] * 1.2
df["Scenario_Low"]  = df["Data_Value"] * 0.8

city_means       = df.groupby("Geo_Place_Name")["Data_Value"].mean()
top_city         = city_means.idxmax()
top_city_avg_val = city_means.max()
# Calculates average pollution for each city and identifies the city with the highest average.

print(f"â–¶ City with highest average pollution: {top_city}")
print(f"  â†’ Average pollution value: {top_city_avg_val:.2f}\n")
#Displays a few records for that city.

# Optional: show a sample of that cityâ€™s records
print(f"â–¶ Sample records for {top_city}:\n")
print(df[df["Geo_Place_Name"] == top_city].head(), "\n")

# â€”â€”â€” 9) TIMEâ€‘TREND (if you have a Date column) â€”â€”â€”
if "Date" in df.columns:
    df["Date"] = pd.to_datetime(df["Date"])
    time_trend = df.groupby("Date")["Data_Value"].mean() 
    #If a Date column exists, it converts it to datetime and calculates average pollution per date.
    print("â–¶ First 10 averageâ€‘overâ€‘time values:\n")
    print(time_trend.head(10), "\n") # Prints the first 10 time-based averages.
    
    plt.figure(figsize=(10, 4))
    plt.plot(time_trend.index, time_trend.values)
    plt.title("Average Pollution Trend Over Time")
    plt.xlabel("Date")
    plt.ylabel("Average Data Value")
    plt.grid(True)
    plt.tight_layout()
    plt.show()  #Displays a line plot of pollution values over time.

# â€”â€”â€” 10) BOXPLOT BY MEASURE â€”â€”â€”
#ðŸ“Š Shows how pollution values vary for each measure:
#Box shows the spread (25%â€“75%)
#Line inside is the median
#Dots outside are outliers
plt.figure(figsize=(12, 6))
sns.boxplot(data=df, x="Measure", y="Data_Value")
plt.title("Boxplot of Data Value by Measure")
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

print("âœ… All outputs printed to terminal and plots displayed interactively.")
#Confirms that all processing and visualization steps were successful.
